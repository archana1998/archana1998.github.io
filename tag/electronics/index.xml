<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Electronics | Archana Swaminathan</title>
    <link>https://archana1998.github.io/tag/electronics/</link>
      <atom:link href="https://archana1998.github.io/tag/electronics/index.xml" rel="self" type="application/rss+xml" />
    <description>Electronics</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Archana Swaminathan, 2020 ©</copyright><lastBuildDate>Sun, 16 Aug 2020 11:03:12 +0530</lastBuildDate>
    <image>
      <url>https://archana1998.github.io/images/icon_hu616effff6bc497e1f3ccd40e4a444d66_14554_512x512_fill_lanczos_center_2.png</url>
      <title>Electronics</title>
      <link>https://archana1998.github.io/tag/electronics/</link>
    </image>
    
    <item>
      <title>Contactless Gesture Recognition</title>
      <link>https://archana1998.github.io/project/gesture-recognition/</link>
      <pubDate>Sun, 16 Aug 2020 11:03:12 +0530</pubDate>
      <guid>https://archana1998.github.io/project/gesture-recognition/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Gesture Recognition Systems are commonly utilized as an interface between computers and humans, along with interacting with many electronic instruments. These systems can be classified into three classes as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Motion-based: When the user holds a device or a controller that detects the gesture made.&lt;/li&gt;
&lt;li&gt;Touch-based: When the system includes a touch-screen and the positions and directions of the finger or equivalent tool of the user are mapped, thus recognizing the gesture.&lt;/li&gt;
&lt;li&gt;Vision-based: When the system makes use of image and signal processing to detect gestures made without touching any device.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The first two types of systems need the users to hold and contact certain devices, for the gesture recognition, and vision-based systems use camera setups, image processing and techniques that involve computer vision. These systems are difficult to set up for small scale use and are also expensive and extremely power hungry. For building a system that needs to function when there are limited resources available, it is important that the setup cost, power consumption and ease and size of setup is taken into consideration. Keeping this in mind, we have built a contactless gesture recognition system that consists of a couple of digital infrared sensors, that have been programmed to do the gesture recognition using a custom algorithm, with an Arduino Uno Microcontroller.&lt;/p&gt;
&lt;h2 id=&#34;problem-solving-methodology&#34;&gt;Problem Solving Methodology&lt;/h2&gt;
&lt;p&gt;Components Used and Setup:
The components we used are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Breadboard&lt;/li&gt;
&lt;li&gt;Arduino Uno Microcontroller&lt;/li&gt;
&lt;li&gt;2 digital IR Sensors&lt;/li&gt;
&lt;li&gt;Jumper wires&lt;/li&gt;
&lt;li&gt;Laptop for interfacing
Languages used:&lt;/li&gt;
&lt;li&gt;Arduino IDE (Based on C++)&lt;/li&gt;
&lt;li&gt;Python (for interfacing sensor output with VLC)&lt;/li&gt;
&lt;/ul&gt;





  
  











&lt;figure id=&#34;figure-setup&#34;&gt;



  &lt;img data-src=&#34;https://archana1998.github.io/project/gesture-recognition/setup_hu3c30132babc4cc16104ed6d6062aecb7_271842_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;966&#34; height=&#34;724&#34;&gt;



  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    Setup
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;We connected two IR sensors to the Breadboard, placed at a distance of approximately 3 cm from each other. These were then interfaced with the Arduino Uno, which was connected to the laptop.&lt;/p&gt;
&lt;p&gt;Voltage is applied to the pair of IR LEDs, which in succession emit Infrared light. This light propagates through the air and once it hits the hand (or object), which acts as a hurdle, it is reflected back to the receiver. The LED on the diode glows, thus indicating that an object has been detected.&lt;/p&gt;
&lt;p&gt;A digital sensor system consists of the sensor itself, a cable, and a transmitter. The sensor has an electronic chip. The measuring signal is directly converted into a digital signal inside the sensor. The data transmission through the cable is also digital. This digital data transmission is not sensitive to cable length, cable resistance or impedance.&lt;/p&gt;
&lt;p&gt;Using the concept of states and delay as in Digital Design, we have created two states of the two sensors each placed on the left and right. These two states are defined and calibrated using a time delay of a few hundred microseconds in the gesture classification algorithm written using the Arduino IDE.&lt;/p&gt;
&lt;p&gt;We have taken two states in the algorithm into consideration namely Q(t) and Q(t+d) where d is the delay defined. The algorithm is defined such that left sensor and right sensor digital values are checked first and then after the defined delay, both sensors are checked for their Boolean values again and therefore the gesture is recognized and printed on the screen after running the code in the Arduino software. The chip on the Arduino Uno board plugs straight into the laptop’s USB port and supports the computer as a virtual serial port.&lt;/p&gt;





  
  











&lt;figure id=&#34;figure-state-table&#34;&gt;



  &lt;img data-src=&#34;https://archana1998.github.io/project/gesture-recognition/table_hu2d1c1a3241fc2a5a508ad4f659b75269_15173_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;486&#34; height=&#34;209&#34;&gt;



  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    State table
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;To make the gesture recognition feature interactive, we have interfaced the output with VLC Media player, so that we can pause, play and rewind/go forward with the playback. To do this interfacing, we have written a Python script, importing the Python library pyautogui, that provides functionality of control of the computer’s keyboard.&lt;/p&gt;
&lt;h2 id=&#34;results-and-conclusions&#34;&gt;Results and Conclusions&lt;/h2&gt;
&lt;p&gt;We tested the gesture recognition system for accuracy by using the precision-recall matric. We took in 30 different samples for input.
The precision is calculated as TP/(TP+FP), where TP denotes the number of true positives and FP denotes the number of false positives.
The precision of our system is = 90% (27 TPs and 3 FPs)&lt;/p&gt;
&lt;p&gt;The recall is calculated as TP/(TP+FN), where TP denotes the number of true positives, and FN denotes the number of false negatives.
The recall of our system is = 86.6% (26 TPs and 4 FNs)&lt;/p&gt;
&lt;p&gt;High precision implies that there is less chances of getting false alarms, and recall expresses the ability to find all relevant information from the dataset.
Practical Applications
We have integrated the recognition system with VLC, to control playback of the video. Similarly, the setup can easily be integrated with any mobile device that is low on resources, as well as used with complex devices, as IR sensors are fundamental in building light reflection systems and are extremely versatile.&lt;/p&gt;
&lt;h2 id=&#34;further-scope&#34;&gt;Further scope&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Friendly user interface that can be easily understood by any user and eventually its application can be extended to more applications like PDF reader, video games etc.&lt;/li&gt;
&lt;li&gt;Computationally inexpensive and low power consuming hardware and software setup, that makes it ideal for integrating with any device, both simple and complex.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;limitations&#34;&gt;Limitations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ambient light obstructs the functioning as is the case with infrared sensors, as they are extremely sensitive. A proper optical barrier must be used to prevent this.&lt;/li&gt;
&lt;li&gt;We have assumed values of time delays between gestures according to what worked well for our test dataset. This leads to the system being slightly inflexible with different speeds of gestures.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
